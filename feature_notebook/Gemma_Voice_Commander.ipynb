{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will server as a Testing notebook for Gemma Voice Commander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first feature will be sending audio message to gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded and encoded sample_audio.wav to base64\n",
      "üöÄ Sending to server with prompt: Transcribe this audio into Hindi\n",
      "Status: 200\n",
      "‚úÖ Response: ‡§Æ‡§æ‡§ú‡•Ä, ‡•õ‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è ‡§™‡•ç‡§≤‡•Ä‡•õ‡•§\n",
      "Prompt used: Transcribe this audio into Hindi\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "SERVER_URL = \"https://ztppbk304fblku-8888.proxy.runpod.net/\"\n",
    "\n",
    "def test_local_wav_audio():\n",
    "    \"\"\"Test local WAV audio with custom prompt\"\"\"\n",
    "    audio_path = \"sample_audio.wav\"  # Use WAV format instead of MP3\n",
    "    prompt = \"Transcribe this audio into Hindi\"\n",
    "    \n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        \n",
    "        audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "        print(f\"‚úÖ Loaded and encoded {audio_path} to base64\")\n",
    "        \n",
    "        data = {\n",
    "            \"data\": audio_base64,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "        \n",
    "        print(f\"üöÄ Sending to server with prompt: {prompt}\")\n",
    "        response = requests.post(\n",
    "            f\"{SERVER_URL}/ask\",\n",
    "            json=data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ Response: {result['text']}\")\n",
    "            print(f\"Prompt used: {result.get('prompt_used', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Server error: {response.text}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {audio_path} not found. Please convert your MP3 to WAV format.\")\n",
    "        print(\"üí° You can convert MP3 to WAV using:\")\n",
    "        print(\"   - Online converters\")\n",
    "        print(\"   - FFmpeg: ffmpeg -i sample_audio.mp3 sample_audio.wav\")\n",
    "        print(\"   - Audacity (free audio editor)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "def test_google_wav_audio():\n",
    "    \"\"\"Test with Google's working WAV file\"\"\"\n",
    "    print(\"üéµ Testing with Google's WAV file...\")\n",
    "    \n",
    "    audio_url = \"https://ai.google.dev/gemma/docs/audio/roses-are.wav\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(audio_url, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Failed to download audio: {response.status_code}\")\n",
    "            return\n",
    "        \n",
    "        print(\"‚úÖ Downloaded Google's WAV file\")\n",
    "        \n",
    "        audio_base64 = base64.b64encode(response.content).decode('utf-8')\n",
    "        print(f\"‚úÖ Converted to base64 ({len(audio_base64)} chars)\")\n",
    "        \n",
    "        data = {\n",
    "            \"data\": audio_base64,\n",
    "            \"prompt\": \"Translate this audio into English\"\n",
    "        }\n",
    "        \n",
    "        print(\"üöÄ Sending to server...\")\n",
    "        server_response = requests.post(\n",
    "            f\"{SERVER_URL}/ask\",\n",
    "            json=data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        print(f\"Status: {server_response.status_code}\")\n",
    "        \n",
    "        if server_response.status_code == 200:\n",
    "            result = server_response.json()\n",
    "            print(f\"‚úÖ Response: {result['text']}\")\n",
    "            print(f\"‚úÖ Prompt used: {result['prompt_used']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Server error: {server_response.text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    choice = input(\"Choose test:\\n1. Local WAV file\\n2. Google's WAV file\\nEnter choice (1-2): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        test_local_wav_audio()\n",
    "    else:\n",
    "        test_google_wav_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded sample_audio.wav\n",
      "üöÄ Comparing both methods...\n",
      "Status: 200\n",
      "\n",
      "üìä COMPARISON RESULTS:\n",
      "OLD method: ‡§Æ‡•Å‡§ù‡•á ‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§º‡§æ‡§á‡§≤ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?\n",
      "NEW method: ‡§ú‡§Ø ‡§Æ‡§æ‡§Å ‡§ú‡•Ä, ‡•õ‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è ‡§™‡•ç‡§≤‡•Ä‡•õ‡•§\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "SERVER_URL = \"https://ztppbk304fblku-8888.proxy.runpod.net/\"\n",
    "\n",
    "def test_improved_audio():\n",
    "    \"\"\"Test audio with NEW preprocessing for better accuracy\"\"\"\n",
    "    audio_path = \"sample_audio.wav\"\n",
    "    prompt = \"Transcribe this audio into Hindi\"\n",
    "    \n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        \n",
    "        audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "        print(f\"‚úÖ Loaded and encoded {audio_path} to base64\")\n",
    "        \n",
    "        data = {\n",
    "            \"data\": audio_base64,\n",
    "            \"prompt\": prompt,\n",
    "            \"enable_preprocessing\": True  # NEW: Enable preprocessing for better accuracy\n",
    "        }\n",
    "        \n",
    "        print(f\"üöÄ Sending to server with IMPROVED processing...\")\n",
    "        response = requests.post(\n",
    "            f\"{SERVER_URL}ask\",\n",
    "            json=data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ IMPROVED Response: {result['text']}\")\n",
    "            print(f\"Status: {result['status']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Server error: {response.text}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {audio_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "def test_old_audio():\n",
    "    \"\"\"Test audio without preprocessing (your old method)\"\"\"\n",
    "    audio_path = \"sample_audio.wav\"\n",
    "    prompt = \"Transcribe this audio into Hindi\"\n",
    "    \n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        \n",
    "        audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "        print(f\"‚úÖ Loaded and encoded {audio_path} to base64\")\n",
    "        \n",
    "        data = {\n",
    "            \"data\": audio_base64,\n",
    "            \"prompt\": prompt,\n",
    "            \"enable_preprocessing\": False  # Disable preprocessing\n",
    "        }\n",
    "        \n",
    "        print(f\"üöÄ Sending to server with OLD processing...\")\n",
    "        response = requests.post(\n",
    "            f\"{SERVER_URL}ask\",\n",
    "            json=data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ OLD Response: {result['text']}\")\n",
    "            print(f\"Status: {result['status']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Server error: {response.text}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {audio_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "def compare_both():\n",
    "    \"\"\"Compare both methods side by side\"\"\"\n",
    "    audio_path = \"sample_audio.wav\"\n",
    "    prompt = \"Transcribe this audio into Hindi\"\n",
    "    \n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        \n",
    "        audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "        print(f\"‚úÖ Loaded {audio_path}\")\n",
    "        \n",
    "        data = {\n",
    "            \"data\": audio_base64,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "        \n",
    "        print(f\"üöÄ Comparing both methods...\")\n",
    "        response = requests.post(\n",
    "            f\"{SERVER_URL}compare_audio\",\n",
    "            json=data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=120\n",
    "        )\n",
    "        \n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            old_result = result['comparison_results']['without_preprocessing']['text']\n",
    "            new_result = result['comparison_results']['with_preprocessing']['text']\n",
    "            \n",
    "            print(f\"\\nüìä COMPARISON RESULTS:\")\n",
    "            print(f\"OLD method: {old_result}\")\n",
    "            print(f\"NEW method: {new_result}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå Server error: {response.text}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {audio_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    choice = input(\"Choose test:\\n1. NEW improved audio processing\\n2. OLD audio processing\\n3. Compare both\\nEnter choice (1-3): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        test_improved_audio()\n",
    "    elif choice == \"2\":\n",
    "        test_old_audio()\n",
    "    else:\n",
    "        compare_both()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ OLD METHOD (10 calls):\n",
      "1: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "2: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "3: ‡§Æ‡•Å‡§ù‡•á ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "4: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "5: ‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§è, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§∏‡§Æ‡§ù ‡§™‡§æ‡§Ø‡§æ‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¶‡•ã‡§π‡§∞‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?\n",
      "6: ‡§ú‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\n",
      "7: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "8: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\n",
      "9: ‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•á‡§¶ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•à‡§Ç ‡§á‡§∏ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§π‡•Ç‡§Ç, ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§®‡§π‡•Ä‡§Ç‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§Ü‡§™ ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§ï‡§∞‡§µ‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?\n",
      "10: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\n",
      "\n",
      "üü¢ NEW METHOD (10 calls):\n",
      "1: ‡§Æ‡•Å‡§ù‡•á ‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•à‡§Ç ‡§á‡§∏ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§è‡§ï ‡§¶‡•ã‡§π‡§∞‡§æ‡§µ ‡§µ‡§æ‡§≤‡§æ ‡§∂‡•ã‡§∞ ‡§π‡•à ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∂‡§¨‡•ç‡§¶ ‡§Ø‡§æ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§\n",
      "\n",
      "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§ï‡•ã‡§à ‡§Ö‡§®‡•ç‡§Ø ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§º‡§æ‡§á‡§≤ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§Æ‡•à‡§Ç ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§ï‡§∞ ‡§∏‡§ï‡•Ç‡§Å?\n",
      "2: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "3: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§á‡§∏ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§≠‡§æ‡§∑‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§\n",
      "4: ‡§ú‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "5: ‡§Æ‡•Å‡§ù‡•á ‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•à‡§Ç‡§®‡•á ‡§ú‡•ã ‡§∏‡•Å‡§®‡§æ ‡§â‡§∏‡•á ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§ï‡•ç‡§∞‡§Æ‡§¨‡§¶‡•ç‡§ß ‡§î‡§∞ ‡§¶‡•ã‡§π‡§∞‡§æ‡§µ ‡§µ‡§æ‡§≤‡§æ ‡§ß‡•ç‡§µ‡§®‡§ø ‡§π‡•à, ‡§ú‡•ã ‡§ï‡§ø‡§∏‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∂‡§¨‡•ç‡§¶ ‡§Ø‡§æ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§§‡•ç‡§µ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§\n",
      "6: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\n",
      "7: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\n",
      "8: ‡§Æ‡•à‡§Ç ‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ø‡§π ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§º‡§æ‡§á‡§≤ ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Ø‡§æ ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•Ç‡§Å‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?\n",
      "9: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§Ø‡•á‡•§\n",
      "10: ‡§ú\n",
      "\n",
      "üìä SUMMARY:\n",
      "OLD unique responses: 7\n",
      "NEW unique responses: 8\n"
     ]
    }
   ],
   "source": [
    "# Audio Data Benchmarking\n",
    "\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "\n",
    "SERVER_URL = \"https://ztppbk304fblku-8888.proxy.runpod.net/\"\n",
    "\n",
    "def run_10_tests():\n",
    "    audio_path = \"sample_audio2.wav\"\n",
    "    prompt = \"Transcribe this audio into Hindi\"\n",
    "    \n",
    "    # Load audio\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "    audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "    \n",
    "    print(\"üî¥ OLD METHOD (10 calls):\")\n",
    "    old_results = []\n",
    "    for i in range(10):\n",
    "        data = {\"data\": audio_base64, \"prompt\": prompt, \"enable_preprocessing\": False}\n",
    "        response = requests.post(f\"{SERVER_URL}ask\", json=data, timeout=60)\n",
    "        result = response.json()['text'] if response.status_code == 200 else \"ERROR\"\n",
    "        old_results.append(result)\n",
    "        print(f\"{i+1}: {result}\")\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(\"\\nüü¢ NEW METHOD (10 calls):\")\n",
    "    new_results = []\n",
    "    for i in range(10):\n",
    "        data = {\"data\": audio_base64, \"prompt\": prompt, \"enable_preprocessing\": True}\n",
    "        response = requests.post(f\"{SERVER_URL}ask\", json=data, timeout=60)\n",
    "        result = response.json()['text'] if response.status_code == 200 else \"ERROR\"\n",
    "        new_results.append(result)\n",
    "        print(f\"{i+1}: {result}\")\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(f\"\\nüìä SUMMARY:\")\n",
    "    print(f\"OLD unique responses: {len(set(old_results))}\")\n",
    "    print(f\"NEW unique responses: {len(set(new_results))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_10_tests()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded sample_audio.wav\n",
      "‚è≠Ô∏è Testing with NO preprocessing...\n",
      "Status: 200\n",
      "‚úÖ Result: ‡§ú‡§Æ‡§æ ‡§ú‡•Ä ‡•õ‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è ‡§™‡•ç‡§≤‡•Ä‡§ú‡•§\n",
      "üîß Processing Applied: False\n",
      "üìã Status: ‚úÖ Adaptive processing: No preprocessing needed (good quality audio)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "SERVER_URL = \"https://ztppbk304fblku-8888.proxy.runpod.net/\"\n",
    "\n",
    "def test_no_processing():\n",
    "    \"\"\"Test audio with NO preprocessing - force it off\"\"\"\n",
    "    audio_path = \"sample_audio.wav\"\n",
    "    prompt = \"Transcribe this audio into Hindi\"\n",
    "    \n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        \n",
    "        audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "        print(f\"‚úÖ Loaded {audio_path}\")\n",
    "        \n",
    "        data = {\n",
    "            \"data\": audio_base64,\n",
    "            \"prompt\": prompt,\n",
    "            \"processing_mode\": \"force_off\"  # Force NO preprocessing\n",
    "        }\n",
    "        \n",
    "        print(f\"‚è≠Ô∏è Testing with NO preprocessing...\")\n",
    "        response = requests.post(\n",
    "            f\"{SERVER_URL}ask\",\n",
    "            json=data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ Result: {result['text']}\")\n",
    "            print(f\"üîß Processing Applied: {result['processing_applied']}\")\n",
    "            print(f\"üìã Status: {result['status']}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response.text}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {audio_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_no_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "Zone info: {'zone': 'B'}\n",
      "{'success': True, 'transcription': '‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§', 'zone': 'Mela Zone B'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import time\n",
    "\n",
    "SERVER_URL = \"https://ztppbk304fblku-8888.proxy.runpod.net/\"\n",
    "\n",
    "def transcribe_audio(audio_path, prompt=\"Transcribe this audio\"):\n",
    "    \"\"\"Get transcription from audio\"\"\"\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "    \n",
    "    audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "    \n",
    "    data = {\"data\": audio_base64, \"prompt\": prompt}\n",
    "    \n",
    "    response = requests.post(f\"{SERVER_URL}/ask\", json=data, timeout=60)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"text\"]\n",
    "    else:\n",
    "        raise Exception(f\"Transcription failed: {response.text}\")\n",
    "\n",
    "def extract_zone_info(text):\n",
    "    \"\"\"Extract zone information from transcribed text\"\"\"\n",
    "    prompt = f\"\"\"Extract the zone information from this text. Return ONLY the zone letter/number. No other text.\n",
    "\n",
    "Example:\n",
    "Input: \"‡§ú‡§Æ‡§æ ‡§ú‡•Ä ‡§ú‡§º‡•ã‡§® ‡§∏‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è ‡§™‡•ç‡§≤‡•Ä‡§ú‡•§\"\n",
    "Output: C\n",
    "\n",
    "Input: \"{text}\"\n",
    "Output:\"\"\"\n",
    "\n",
    "    data = {\"prompt\": prompt, \"max_tokens\": 10,\"processing_mode\": \"force_off\" }\n",
    "    \n",
    "    response = requests.post(f\"{SERVER_URL}/generate\", json=data, timeout=30)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        zone = response.json()[\"text\"].strip()\n",
    "        if zone and len(zone) <= 5:  # Valid zone should be short\n",
    "            return {\"zone\": zone}\n",
    "    \n",
    "    return None  # Failed to extract\n",
    "\n",
    "def process_audio(audio_path):\n",
    "    \"\"\"Main function with retry logic\"\"\"\n",
    "    \n",
    "    # Step 1: Transcribe\n",
    "    transcription = transcribe_audio(audio_path)\n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    \n",
    "    # Step 2: Extract zone with retries\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            zone_info = extract_zone_info(transcription)\n",
    "            print(f\"Zone info: {zone_info}\")\n",
    "            \n",
    "            # Check if zone extraction was successful AND valid\n",
    "            if zone_info and zone_info.get(\"zone\") and zone_info[\"zone\"].lower() not in [\"none\", \"unknown\", \"‡§®/‡§è\"]:\n",
    "                final_zone_info = \"Mela Zone \" + zone_info[\"zone\"]\n",
    "                return {\"success\": True, \"transcription\": transcription, \"zone\": final_zone_info}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if attempt < 4:  # Don't sleep on last attempt\n",
    "            time.sleep(1)\n",
    "    \n",
    "    # All retries failed\n",
    "    return {\"success\": False, \"message\": \"please Re-record the audio\", \"transcription\": transcription}\n",
    "\n",
    "# Test it\n",
    "if __name__ == \"__main__\":\n",
    "    result = process_audio(\"sample_audio2.wav\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 session files\n",
      "Created DataFrame with 43 rows\n",
      "Saved to sessions_data.csv\n",
      "  session_id     location  operator_name   status           created_at  \\\n",
      "0   0191ad47  Mela Zone B  Security Team  created  2025-07-01 09:37:23   \n",
      "1   090bd251  Mela Zone B  Security Team  created  2025-07-01 09:48:15   \n",
      "2   0c801c0e  Mela Zone B  Security Team  created  2025-07-02 04:39:38   \n",
      "3   109561c0  Mela Zone B  Security Team  created  2025-07-01 15:35:39   \n",
      "4   1118ba2f  Mela Zone B  Security Team  created  2025-07-01 10:54:16   \n",
      "\n",
      "   frames_analyzed  frames_flagged  risk_score  \\\n",
      "0               12               0         0.0   \n",
      "1                6               0         0.0   \n",
      "2                6               6       100.0   \n",
      "3                5               0         0.0   \n",
      "4               11               0         0.0   \n",
      "\n",
      "                                  gcs_path        last_analysis  ...  \\\n",
      "0  gs://gemma3n-raw/sessions/0191ad47.json  2025-07-01 09:37:55  ...   \n",
      "1  gs://gemma3n-raw/sessions/090bd251.json  2025-07-01 09:48:28  ...   \n",
      "2  gs://gemma3n-raw/sessions/0c801c0e.json  2025-07-02 04:40:07  ...   \n",
      "3  gs://gemma3n-raw/sessions/109561c0.json  2025-07-01 15:36:00  ...   \n",
      "4  gs://gemma3n-raw/sessions/1118ba2f.json  2025-07-01 10:54:44  ...   \n",
      "\n",
      "   density_unknown  motion_calm  motion_chaotic  motion_unknown  risk_safe  \\\n",
      "0             12.0          0.0             0.0            12.0       12.0   \n",
      "1              6.0          0.0             0.0             6.0        6.0   \n",
      "2              0.0          0.0             6.0             0.0        0.0   \n",
      "3              5.0          0.0             0.0             5.0        5.0   \n",
      "4              0.0         11.0             0.0             0.0       11.0   \n",
      "\n",
      "   risk_moderate  risk_high  risk_critical  \\\n",
      "0            0.0        0.0            0.0   \n",
      "1            0.0        0.0            0.0   \n",
      "2            0.0        0.0            6.0   \n",
      "3            0.0        0.0            0.0   \n",
      "4            0.0        0.0            0.0   \n",
      "\n",
      "                                      flagged_frames  email_sent  \n",
      "0                                                NaN         NaN  \n",
      "1                                                NaN         NaN  \n",
      "2  [{'frame_number': 1, 'gcs_path': 'gs://gemma3n...        True  \n",
      "3                                                NaN         NaN  \n",
      "4                                                NaN         NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gcs_key.json\"\n",
    "\n",
    "BUCKET_NAME = \"gemma3n-raw\"\n",
    "SESSIONS_PREFIX = \"sessions/\"\n",
    "\n",
    "def process_sessions():\n",
    "    \"\"\"Read all session JSONs from GCS and create DataFrame\"\"\"\n",
    "    \n",
    "    # Get GCS client\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(BUCKET_NAME)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    blobs = bucket.list_blobs(prefix=SESSIONS_PREFIX)\n",
    "    json_files = [blob for blob in blobs if blob.name.endswith('.json')]\n",
    "    \n",
    "    print(f\"Found {len(json_files)} session files\")\n",
    "    \n",
    "    # Read each JSON and flatten\n",
    "    all_data = []\n",
    "    for blob in json_files:\n",
    "        try:\n",
    "            content = blob.download_as_text()\n",
    "            data = json.loads(content)\n",
    "            \n",
    "            # Flatten nested data\n",
    "            flat_data = {**data}  # Copy all top-level fields\n",
    "            \n",
    "            # Flatten analysis_breakdown if exists\n",
    "            if 'analysis_breakdown' in data:\n",
    "                breakdown = data['analysis_breakdown']\n",
    "                \n",
    "                if 'density_stats' in breakdown:\n",
    "                    for key, value in breakdown['density_stats'].items():\n",
    "                        flat_data[f'density_{key.lower()}'] = value\n",
    "                \n",
    "                if 'motion_stats' in breakdown:\n",
    "                    for key, value in breakdown['motion_stats'].items():\n",
    "                        flat_data[f'motion_{key.lower()}'] = value\n",
    "                \n",
    "                if 'risk_levels' in breakdown:\n",
    "                    for key, value in breakdown['risk_levels'].items():\n",
    "                        flat_data[f'risk_{key.lower()}'] = value\n",
    "                \n",
    "                # Remove original nested field\n",
    "                del flat_data['analysis_breakdown']\n",
    "            \n",
    "            all_data.append(flat_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {blob.name}: {e}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(f\"Created DataFrame with {len(df)} rows\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(\"sessions_data.csv\", index=False)\n",
    "    print(\"Saved to sessions_data.csv\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = process_sessions()\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: ‡•õ‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§\n",
      "Zone info: {'zone': 'B'}\n",
      "üîç Querying database for Mela Zone B...\n",
      "üìñ Loaded 43 sessions from database\n",
      "üîç Found 43 sessions for Mela Zone B\n",
      "üìÖ Latest session: c59e06d8 from 2025-07-03 14:30:40\n",
      "üó£Ô∏è Generating Hindi message...\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT:\n",
      "==================================================\n",
      "Zone: Mela Zone B\n",
      "Hindi Message: ‡§†‡•Ä‡§ï ‡§π‡•à, ‡§Ø‡§π‡§æ‡§Å ‡§è‡§ï ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§ø‡§§ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§π‡•à, ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à:\n",
      "\n",
      "\"‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞‡•§ ‡§Ø‡§π ‡§Æ‡•á‡§≤‡§æ ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§Ö‡§™‡§°‡•á‡§ü ‡§π‡•à‡•§ ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∏‡•ç‡§•‡§ø‡§§‡§ø **‡§ó‡§Ç‡§≠‡•Ä‡§∞** ‡§π‡•à‡•§ ‡§∞‡§ø‡§∏‡•ç‡§ï ‡§∏‡•ç‡§ï‡•ã‡§∞ 100% ‡§π‡•à, ‡§ú‡•ã ‡§ï‡§ø ‡§¨‡§π‡•Å‡§§ ‡§ö‡§ø‡§Ç‡§§‡§æ‡§ú‡§®‡§ï ‡§π‡•à‡•§ ‡§π‡§Æ‡§®‡•á 11 ‡§´‡•ç‡§∞‡•á‡§Æ ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§ø‡§Ø‡§æ, ‡§ú‡§ø‡§®‡§Æ‡•á‡§Ç ‡§∏‡•á 10 ‡§∏‡§Ç‡§¶‡§ø‡§ó‡•ç‡§ß ‡§™‡§æ‡§è ‡§ó‡§è ‡§π‡•à‡§Ç‡•§ \n",
      "\n",
      "‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§Æ‡•á‡§Ç ‡§â‡§ö‡•ç‡§ö ‡§ò‡§®‡§§‡•ç‡§µ ‡§µ‡§æ‡§≤‡•á 9 ‡§ò‡§ü‡§®‡§æ‡§è‡§Å, ‡§Ö‡§∞‡§æ‡§ú‡§ï ‡§ó‡§§‡§ø ‡§µ‡§æ‡§≤‡•Ä 10 ‡§ò‡§ü‡§®‡§æ‡§è‡§Å ‡§î‡§∞ 9 ‡§ó‡§Ç‡§≠‡•Ä‡§∞ ‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§µ‡§æ‡§≤‡•Ä ‡§ò‡§ü‡§®‡§æ‡§è‡§Å ‡§™‡§æ‡§à ‡§ó‡§à ‡§π‡•à‡§Ç‡•§ \n",
      "\n",
      "‡§á‡§∏‡§≤‡§ø‡§è, ‡§ú‡§º‡•ã‡§® ‡§Æ‡•á‡§Ç **‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§∞‡§µ‡§æ‡§à** ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ü‡•Ä‡§Æ ‡§á‡§∏ ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§Ö‡§™‡§°‡•á‡§ü 3 ‡§ú‡•Å‡§≤‡§æ‡§à, 2025 ‡§ï‡•ã ‡§¶‡•ã‡§™‡§π‡§∞\n",
      "\n",
      "Raw Update:\n",
      "üõ°Ô∏è Mela Zone B Security Update\n",
      "\n",
      "üìä Current Status: üî¥ CRITICAL\n",
      "üìà Risk Score: 100.0%\n",
      "üë• Frames Analyzed: 11\n",
      "‚ö†Ô∏è Frames Flagged: 10 (90.9%)\n",
      "üïí Last Updated: 2025-07-03 14:30:40\n",
      "üë§ Operator: Security Team\n",
      "üÜî Session: c59e06d8\n",
      "\n",
      "üìã Analysis Details:\n",
      "‚Ä¢ High Density Events: 9.0\n",
      "‚Ä¢ Chaotic Motion Events: 10.0  \n",
      "‚Ä¢ Critical Risk Events: 9.0\n",
      "\n",
      "Status: Zone is currently IMMEDIATE ACTION REQUIRED.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "SERVER_URL = \"https://ztppbk304fblku-8888.proxy.runpod.net/\"\n",
    "\n",
    "def transcribe_audio(audio_path, prompt=\"Transcribe this audio\"):\n",
    "    \"\"\"Get transcription from audio\"\"\"\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "    \n",
    "    audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "    \n",
    "    data = {\"data\": audio_base64, \"prompt\": prompt}\n",
    "    \n",
    "    response = requests.post(f\"{SERVER_URL}/ask\", json=data, timeout=60)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"text\"]\n",
    "    else:\n",
    "        raise Exception(f\"Transcription failed: {response.text}\")\n",
    "\n",
    "def extract_zone_info(text):\n",
    "    \"\"\"Extract zone information from transcribed text\"\"\"\n",
    "    prompt = f\"\"\"Extract the zone information from this text. Return ONLY the zone letter/number. No other text.\n",
    "\n",
    "Example:\n",
    "Input: \"‡§ú‡§Æ‡§æ ‡§ú‡•Ä ‡§ú‡§º‡•ã‡§® ‡§∏‡•Ä ‡§ï‡•Ä ‡§∏‡§ø‡§ï‡•ç‡§Ø‡•ã‡§∞‡§ø‡§ü‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§¶‡•Ä‡§ú‡§ø‡§è ‡§™‡•ç‡§≤‡•Ä‡§ú‡•§\"\n",
    "Output: C\n",
    "\n",
    "Input: \"‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä ‡§ï‡•Ä ‡§Ö‡§™‡§°‡•á‡§ü ‡§ö‡§æ‡§π‡§ø‡§è\"\n",
    "Output: B\n",
    "\n",
    "Input: \"{text}\"\n",
    "Output:\"\"\"\n",
    "\n",
    "    data = {\"prompt\": prompt, \"max_tokens\": 10,\"processing_mode\": \"force_off\" }\n",
    "    \n",
    "    response = requests.post(f\"{SERVER_URL}/generate\", json=data, timeout=30)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        zone = response.json()[\"text\"].strip()\n",
    "        # Only accept single English letters/numbers\n",
    "        if zone and len(zone) <= 2 and zone.isalnum():\n",
    "            return {\"zone\": zone}\n",
    "    \n",
    "    return None  # Failed to extract\n",
    "\n",
    "def generate_hindi_message(zone_update_data):\n",
    "    \"\"\"Generate user-friendly Hindi message using LLM\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"Convert this security update data into a natural, user-friendly Hindi message for voice response. Make it conversational and easy to understand.\n",
    "\n",
    "Data: {zone_update_data}\n",
    "\n",
    "Instructions:\n",
    "- Convert to natural Hindi \n",
    "- Make it sound like a security officer giving an update\n",
    "- Keep it concise but informative\n",
    "- Include key status and numbers\n",
    "- Sound professional but friendly\n",
    "- Do NOT say \"‡§ú‡•Ä ‡§π‡§æ‡§Å, ‡§ú‡§º‡•ã‡§® ‡§¨‡•Ä\" - just give the update directly\n",
    "- Start with the current status\n",
    "\n",
    "Example style: \"‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§π‡•à‡•§ ‡§∞‡§ø‡§∏‡•ç‡§ï ‡§∏‡•ç‡§ï‡•ã‡§∞ 15% ‡§π‡•à ‡§î‡§∞ ‡§ï‡•ã‡§à ‡§ñ‡§§‡§∞‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§\"\n",
    "\n",
    "Hindi Message:\"\"\"\n",
    "\n",
    "        data = {\"prompt\": prompt, \"max_tokens\": 150}\n",
    "        \n",
    "        response = requests.post(f\"{SERVER_URL}/generate\", json=data, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            hindi_message = response.json()[\"text\"].strip()\n",
    "            return hindi_message\n",
    "        else:\n",
    "            return \"‡§Ö‡§™‡§°‡•á‡§ü ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return \"‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§Ö‡§™‡§°‡•á‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤ ‡§∏‡§ï‡§æ‡•§\"\n",
    "\n",
    "def get_zone_update(zone_name):\n",
    "    \"\"\"Get latest update for the zone from database\"\"\"\n",
    "    try:\n",
    "        # ===== PANDAS DATABASE QUERYING SECTION =====\n",
    "        \n",
    "        # 1. Load the processed sessions data from CSV\n",
    "        df = pd.read_csv(\"sessions_data.csv\")\n",
    "        print(f\"üìñ Loaded {len(df)} sessions from database\")\n",
    "        \n",
    "        # 2. Convert timestamp columns to datetime for proper sorting\n",
    "        df['last_analysis'] = pd.to_datetime(df['last_analysis'], errors='coerce')\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "        \n",
    "        # 3. Filter DataFrame to find sessions for the requested zone\n",
    "        zone_sessions = df[df['location'] == zone_name]\n",
    "        print(f\"üîç Found {len(zone_sessions)} sessions for {zone_name}\")\n",
    "        \n",
    "        # 4. Check if zone exists in database\n",
    "        if zone_sessions.empty:\n",
    "            return f\"‚ùå No data found for {zone_name}. Available zones: {df['location'].unique().tolist()}\"\n",
    "        \n",
    "        # 5. Sort by last_analysis timestamp and get the most recent session\n",
    "        latest_session = zone_sessions.sort_values('last_analysis', ascending=True).iloc[-1]\n",
    "        print(f\"üìÖ Latest session: {latest_session['session_id']} from {latest_session['last_analysis']}\")\n",
    "        \n",
    "        # 6. Extract all relevant data from the latest session row\n",
    "        session_id = latest_session['session_id']\n",
    "        risk_score = latest_session['risk_score']\n",
    "        frames_analyzed = latest_session['frames_analyzed']\n",
    "        frames_flagged = latest_session['frames_flagged']\n",
    "        last_update = latest_session['last_analysis']\n",
    "        operator_name = latest_session.get('operator_name', 'Security Team')\n",
    "        \n",
    "        # 7. Calculate additional metrics from the data\n",
    "        flagging_rate = (frames_flagged / frames_analyzed * 100) if frames_analyzed > 0 else 0\n",
    "        \n",
    "        # 8. Get breakdown stats if available (these are the flattened columns)\n",
    "        density_high = latest_session.get('density_high', 0)\n",
    "        motion_chaotic = latest_session.get('motion_chaotic', 0)\n",
    "        risk_critical = latest_session.get('risk_critical', 0)\n",
    "        \n",
    "        # ===== END OF PANDAS QUERYING SECTION =====\n",
    "        \n",
    "        # Determine risk status based on score\n",
    "        if risk_score <= 15:\n",
    "            status = \"üü¢ SAFE\"\n",
    "            status_msg = \"operating normally\"\n",
    "        elif risk_score <= 40:\n",
    "            status = \"üü° WATCH\"\n",
    "            status_msg = \"under routine monitoring\"\n",
    "        elif risk_score <= 70:\n",
    "            status = \"üü† ALERT\"\n",
    "            status_msg = \"requires attention\"\n",
    "        else:\n",
    "            status = \"üî¥ CRITICAL\"\n",
    "            status_msg = \"IMMEDIATE ACTION REQUIRED\"\n",
    "        \n",
    "        # Create comprehensive update message\n",
    "        message = f\"\"\"\n",
    "üõ°Ô∏è {zone_name} Security Update\n",
    "\n",
    "üìä Current Status: {status}\n",
    "üìà Risk Score: {risk_score}%\n",
    "üë• Frames Analyzed: {frames_analyzed}\n",
    "‚ö†Ô∏è Frames Flagged: {frames_flagged} ({flagging_rate:.1f}%)\n",
    "üïí Last Updated: {last_update.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "üë§ Operator: {operator_name}\n",
    "üÜî Session: {session_id}\n",
    "\n",
    "üìã Analysis Details:\n",
    "‚Ä¢ High Density Events: {density_high}\n",
    "‚Ä¢ Chaotic Motion Events: {motion_chaotic}  \n",
    "‚Ä¢ Critical Risk Events: {risk_critical}\n",
    "\n",
    "Status: Zone is currently {status_msg}.\n",
    "\"\"\"\n",
    "        \n",
    "        return message.strip()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return \"‚ùå Database file 'sessions_data.csv' not found. Please run the data processor first.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error retrieving update for {zone_name}: {str(e)}\"\n",
    "\n",
    "def process_audio(audio_path):\n",
    "    \"\"\"Main function with retry logic\"\"\"\n",
    "    \n",
    "    # Step 1: Transcribe\n",
    "    transcription = transcribe_audio(audio_path)\n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    \n",
    "    # Step 2: Extract zone with retries\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            zone_info = extract_zone_info(transcription)\n",
    "            print(f\"Zone info: {zone_info}\")\n",
    "            \n",
    "            # Check if zone extraction was successful AND valid\n",
    "            if zone_info and zone_info.get(\"zone\") and zone_info[\"zone\"].lower() not in [\"none\", \"unknown\", \"‡§®/‡§è\"]:\n",
    "                final_zone_info = \"Mela Zone \" + zone_info[\"zone\"]\n",
    "                \n",
    "                # Step 3: Get zone update from database\n",
    "                print(f\"üîç Querying database for {final_zone_info}...\")\n",
    "                zone_update = get_zone_update(final_zone_info)\n",
    "                \n",
    "                # Step 4: Generate Hindi message using LLM\n",
    "                print(f\"üó£Ô∏è Generating Hindi message...\")\n",
    "                hindi_message = generate_hindi_message(zone_update)\n",
    "                \n",
    "                return {\n",
    "                    \"success\": True, \n",
    "                    \"transcription\": transcription, \n",
    "                    \"zone\": final_zone_info,\n",
    "                    \"raw_update\": zone_update,\n",
    "                    \"hindi_message\": hindi_message\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            pass\n",
    "        \n",
    "        if attempt < 4:  # Don't sleep on last attempt\n",
    "            time.sleep(1)\n",
    "    \n",
    "    # All retries failed\n",
    "    return {\"success\": False, \"message\": \"please Re-record the audio\", \"transcription\": transcription}\n",
    "\n",
    "# Test it\n",
    "if __name__ == \"__main__\":\n",
    "    result = process_audio(\"sample_audio2.wav\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULT:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(f\"Zone: {result['zone']}\")\n",
    "        print(f\"Hindi Message: {result['hindi_message']}\")\n",
    "        print(f\"\\nRaw Update:\\n{result['raw_update']}\")\n",
    "    else:\n",
    "        print(f\"Failed: {result['message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
